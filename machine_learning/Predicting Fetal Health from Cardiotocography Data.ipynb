{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Fetal Health from Cardiotocography Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "#### What is CTG?\n",
    "\n",
    "Cardiotocography (CTG) is a technique used during pregnancy to visually represent the fetal heart rate and uterine contractions. The main purpose of this kind of monitoring is to asses the fetal health in late pregnancy and during labour and to allow detection of fetal distress.\n",
    "\n",
    "According to the consensus guidelines made by the International Federation of Gynecology and Obstetrics (FIGO) the basic CTG features include baseline, variability, accelerations, decelerations and contractions.\n",
    "\n",
    "_Baseline_ is the average heart rate of the fetus within a ten minute window. A value in the range of 110-160 beats per minute (bpm) is considered to be normal.\n",
    "\n",
    "_Variability_ is the variation of fetal heart rate from beat to beat. It is determined by irregular fluctuations in amplitude and frequency in the baseline. A value of 5-25 bpm is normal and indicates an intact neurological system in the fetus.\n",
    "\n",
    "_Acceleration_ refers to abrupt increase in fetal heart rate that peaks at 15 bpm or more above the baseline and lasts 15 seconds or longer. Most accelerations coincide with fetal movement and uterine contractions, which indicates a healthy fetus.\n",
    "\n",
    "_Deceleration_ is the abrupt decrease in fetal heart rate of more than 15 bpm below the baseline for more than 15 seconds. There are early, variable, late and prolonged decelerations. Early decelerations start when the uterine contraction begins and end when it stops. Variable decelerations have a variable recovery phase and may not be linked to uterine contractions. These first two types are not considered pathological. Late decelerations start at the peak of the uterine contraction and recover after the contraction ends. They indicate insufficient blood flow to the uterus and placenta which leads to significantly reduced blood flow to the fetus as well. Prolonged decelerations last for more than 3 minutes and are frequently associated with accute fetal stress.\n",
    "\n",
    "_Contractions_ are bell-shaped gradual increases in the uterine activity signal followed by roughly symmetric decreases, lasting 45âˆ’120 seconds in total. Five or fewer contractions in 10 minutes, averaged over a 30-minute window are considered normal.\n",
    "\n",
    "\n",
    "#### How is CTG data analysed?\n",
    "\n",
    "Interpretation of CTG data is usually done by experienced professionals according to the standardized FIGO guidelines. An automated way to analyse the data is a program called SisPorto developed in the late 1980s at the University of Porto. This type of computerized analysis is based on the same guidelines but includes additional computations of the main features outlined earlier.\n",
    "\n",
    "After evaluation of the basic CTG features the fetal condition is classified as one of three classes - normal, suspicious or parhological.\n",
    "\n",
    " - _Normal_: This condition is characterized with a baseline of 110-160 bpm, variability of 5-25 bpm and no repetitive decelerations. It indicates a fetus with no hypoxia or acidosis and requires no intervention to improve fetal oxygenation state.\n",
    " - _Suspicious_: This condition is lacking at least one characteristic of normality but has no pathological features. It indicates a fetus with a low probability of having hypoxia or acidosis and requires close monitoring or additional methods to evaluate fetal oxygenation.\n",
    " - _Pathological_: This condition is characterized with a baseline of below 100 bpm, reduced or increased variability, or sinusoidal pattern and repetitive late or prolonged decelerations for more than 20-30 min if variability is reduced, or one prolonged deceleration with duration of more than 5 min. It indicates a fetus with a high probability of having hypoxia or acidosis and requires immediate action to correct reversible causes, as well as additional methods to evaluate fetal oxygenation or expedite delivery if this is not possible.\n",
    "\n",
    "\n",
    "### Project Objective\n",
    "\n",
    "The aim of this project is to compare the performance of different classification models in the prediction of one of the three classes described above. Those models will be trained on data obtained from the SisPorto program and use labels classified by three expert obstetricians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering and preparing data for analysis\n",
    "\n",
    "The dataset used in this project is the Kaggle [Fetal Health Classification Dataset](https://www.kaggle.com/andrewmvd/fetal-health-classification), it's original source being the UCI Machine Learning Repository - [\n",
    "Cardiotocography Dataset](https://archive.ics.uci.edu/ml/datasets/cardiotocography). The reason for using the Kaggle dataset is that it has already been transformed in some way to make working with it a bit easier.\n",
    "\n",
    "The dataset contains 2126 observations with 21 attributes and 1 target. Information regarding each attribute is as follows:\n",
    " - `baseline_value` - fetal heart rate (FHR) baseline (beats per minute)\n",
    " - `accelerations` - number of accelerations per second\n",
    " - `fetal_movement` - number of fetal movements per second\n",
    " - `uterine_contractions` - number of uterine contractions per second\n",
    " - `light_decelerations` - number of light decelerations per second\n",
    " - `severe_decelerations` - number of severe decelerations per second\n",
    " - `prolongued_decelerations` - number of prolongued decelerations per second\n",
    " - `short_term_variability_abnormal` - percentage of time with abnormal short term variability\n",
    " - `short_term_variability_mean` - mean value of short term variability\n",
    " - `long_term_variability_abnormal` - percentage of time with abnormal long term variability\n",
    " - `long_term_variability_mean` - mean value of long term variability\n",
    " - `histogram_width` - width of FHR histogram\n",
    " - `histogram_min` - minimum of FHR histogram\n",
    " - `histogram_max` - maximum of FHR histogram\n",
    " - `histogram_number_of_peaks` - number of histogram peaks\n",
    " - `histogram_number_of_zeroes` - number of histogram zeros\n",
    " - `histogram_mode` - histogram mode\n",
    " - `histogram_mean` - histogram mean\n",
    " - `histogram_median` - histogram median\n",
    " - `histogram_variance` - histogram variance\n",
    " - `histogram_tendency` - histogram tendency\n",
    "\n",
    "The target variable `fetal_health` consists of three classes:\n",
    " - class 1 - Normal\n",
    " - class 2 - Suspicious\n",
    " - class 3 - Pathological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>severe_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>...</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>histogram_tendency</th>\n",
       "      <th>fetal_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      baseline value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0              120.0          0.000           0.000                 0.000   \n",
       "1              132.0          0.006           0.000                 0.006   \n",
       "2              133.0          0.003           0.000                 0.008   \n",
       "3              134.0          0.003           0.000                 0.008   \n",
       "4              132.0          0.007           0.000                 0.008   \n",
       "...              ...            ...             ...                   ...   \n",
       "2121           140.0          0.000           0.000                 0.007   \n",
       "2122           140.0          0.001           0.000                 0.007   \n",
       "2123           140.0          0.001           0.000                 0.007   \n",
       "2124           140.0          0.001           0.000                 0.006   \n",
       "2125           142.0          0.002           0.002                 0.008   \n",
       "\n",
       "      light_decelerations  severe_decelerations  prolongued_decelerations  \\\n",
       "0                   0.000                   0.0                       0.0   \n",
       "1                   0.003                   0.0                       0.0   \n",
       "2                   0.003                   0.0                       0.0   \n",
       "3                   0.003                   0.0                       0.0   \n",
       "4                   0.000                   0.0                       0.0   \n",
       "...                   ...                   ...                       ...   \n",
       "2121                0.000                   0.0                       0.0   \n",
       "2122                0.000                   0.0                       0.0   \n",
       "2123                0.000                   0.0                       0.0   \n",
       "2124                0.000                   0.0                       0.0   \n",
       "2125                0.000                   0.0                       0.0   \n",
       "\n",
       "      abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "0                                73.0                                   0.5   \n",
       "1                                17.0                                   2.1   \n",
       "2                                16.0                                   2.1   \n",
       "3                                16.0                                   2.4   \n",
       "4                                16.0                                   2.4   \n",
       "...                               ...                                   ...   \n",
       "2121                             79.0                                   0.2   \n",
       "2122                             78.0                                   0.4   \n",
       "2123                             79.0                                   0.4   \n",
       "2124                             78.0                                   0.4   \n",
       "2125                             74.0                                   0.4   \n",
       "\n",
       "      percentage_of_time_with_abnormal_long_term_variability  ...  \\\n",
       "0                                                  43.0       ...   \n",
       "1                                                   0.0       ...   \n",
       "2                                                   0.0       ...   \n",
       "3                                                   0.0       ...   \n",
       "4                                                   0.0       ...   \n",
       "...                                                 ...       ...   \n",
       "2121                                               25.0       ...   \n",
       "2122                                               22.0       ...   \n",
       "2123                                               20.0       ...   \n",
       "2124                                               27.0       ...   \n",
       "2125                                               36.0       ...   \n",
       "\n",
       "      histogram_min  histogram_max  histogram_number_of_peaks  \\\n",
       "0              62.0          126.0                        2.0   \n",
       "1              68.0          198.0                        6.0   \n",
       "2              68.0          198.0                        5.0   \n",
       "3              53.0          170.0                       11.0   \n",
       "4              53.0          170.0                        9.0   \n",
       "...             ...            ...                        ...   \n",
       "2121          137.0          177.0                        4.0   \n",
       "2122          103.0          169.0                        6.0   \n",
       "2123          103.0          170.0                        5.0   \n",
       "2124          103.0          169.0                        6.0   \n",
       "2125          117.0          159.0                        2.0   \n",
       "\n",
       "      histogram_number_of_zeroes  histogram_mode  histogram_mean  \\\n",
       "0                            0.0           120.0           137.0   \n",
       "1                            1.0           141.0           136.0   \n",
       "2                            1.0           141.0           135.0   \n",
       "3                            0.0           137.0           134.0   \n",
       "4                            0.0           137.0           136.0   \n",
       "...                          ...             ...             ...   \n",
       "2121                         0.0           153.0           150.0   \n",
       "2122                         0.0           152.0           148.0   \n",
       "2123                         0.0           153.0           148.0   \n",
       "2124                         0.0           152.0           147.0   \n",
       "2125                         1.0           145.0           143.0   \n",
       "\n",
       "      histogram_median  histogram_variance  histogram_tendency  fetal_health  \n",
       "0                121.0                73.0                 1.0           2.0  \n",
       "1                140.0                12.0                 0.0           1.0  \n",
       "2                138.0                13.0                 0.0           1.0  \n",
       "3                137.0                13.0                 1.0           1.0  \n",
       "4                138.0                11.0                 1.0           1.0  \n",
       "...                ...                 ...                 ...           ...  \n",
       "2121             152.0                 2.0                 0.0           2.0  \n",
       "2122             151.0                 3.0                 1.0           2.0  \n",
       "2123             152.0                 4.0                 1.0           2.0  \n",
       "2124             151.0                 4.0                 1.0           2.0  \n",
       "2125             145.0                 1.0                 0.0           1.0  \n",
       "\n",
       "[2126 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg_data = pd.read_csv('data/fetal_health.csv')\n",
    "ctg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Some column names need to be changed slightly in order to match the format of the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_data = ctg_data.rename(columns={'baseline value': 'baseline_value', 'abnormal_short_term_variability': 'short_term_variability_abnormal', 'mean_value_of_short_term_variability': 'short_term_variability_mean',\n",
    "                                    'percentage_of_time_with_abnormal_long_term_variability': 'long_term_variability_abnormal', 'mean_value_of_long_term_variability': 'long_term_variability_mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take an overall look at the data and scan for anything that might need initial fixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseline_value                     float64\n",
       "accelerations                      float64\n",
       "fetal_movement                     float64\n",
       "uterine_contractions               float64\n",
       "light_decelerations                float64\n",
       "severe_decelerations               float64\n",
       "prolongued_decelerations           float64\n",
       "short_term_variability_abnormal    float64\n",
       "short_term_variability_mean        float64\n",
       "long_term_variability_abnormal     float64\n",
       "long_term_variability_mean         float64\n",
       "histogram_width                    float64\n",
       "histogram_min                      float64\n",
       "histogram_max                      float64\n",
       "histogram_number_of_peaks          float64\n",
       "histogram_number_of_zeroes         float64\n",
       "histogram_mode                     float64\n",
       "histogram_mean                     float64\n",
       "histogram_median                   float64\n",
       "histogram_variance                 float64\n",
       "histogram_tendency                 float64\n",
       "fetal_health                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2126 entries, 0 to 2125\n",
      "Data columns (total 22 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   baseline_value                   2126 non-null   float64\n",
      " 1   accelerations                    2126 non-null   float64\n",
      " 2   fetal_movement                   2126 non-null   float64\n",
      " 3   uterine_contractions             2126 non-null   float64\n",
      " 4   light_decelerations              2126 non-null   float64\n",
      " 5   severe_decelerations             2126 non-null   float64\n",
      " 6   prolongued_decelerations         2126 non-null   float64\n",
      " 7   short_term_variability_abnormal  2126 non-null   float64\n",
      " 8   short_term_variability_mean      2126 non-null   float64\n",
      " 9   long_term_variability_abnormal   2126 non-null   float64\n",
      " 10  long_term_variability_mean       2126 non-null   float64\n",
      " 11  histogram_width                  2126 non-null   float64\n",
      " 12  histogram_min                    2126 non-null   float64\n",
      " 13  histogram_max                    2126 non-null   float64\n",
      " 14  histogram_number_of_peaks        2126 non-null   float64\n",
      " 15  histogram_number_of_zeroes       2126 non-null   float64\n",
      " 16  histogram_mode                   2126 non-null   float64\n",
      " 17  histogram_mean                   2126 non-null   float64\n",
      " 18  histogram_median                 2126 non-null   float64\n",
      " 19  histogram_variance               2126 non-null   float64\n",
      " 20  histogram_tendency               2126 non-null   float64\n",
      " 21  fetal_health                     2126 non-null   float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 365.5 KB\n"
     ]
    }
   ],
   "source": [
    "ctg_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline_value</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>133.303857</td>\n",
       "      <td>9.840844</td>\n",
       "      <td>106.0</td>\n",
       "      <td>126.000</td>\n",
       "      <td>133.000</td>\n",
       "      <td>140.000</td>\n",
       "      <td>160.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accelerations</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fetal_movement</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.046666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uterine_contractions</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light_decelerations</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_decelerations</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_term_variability_abnormal</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>46.990122</td>\n",
       "      <td>17.192814</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>61.000</td>\n",
       "      <td>87.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_term_variability_mean</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>1.332785</td>\n",
       "      <td>0.883241</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.700</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_variability_abnormal</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>9.846660</td>\n",
       "      <td>18.396880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>91.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_variability_mean</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>8.187629</td>\n",
       "      <td>5.628247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.600</td>\n",
       "      <td>7.400</td>\n",
       "      <td>10.800</td>\n",
       "      <td>50.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_width</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>70.445908</td>\n",
       "      <td>38.955693</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.000</td>\n",
       "      <td>67.500</td>\n",
       "      <td>100.000</td>\n",
       "      <td>180.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_min</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>93.579492</td>\n",
       "      <td>29.560212</td>\n",
       "      <td>50.0</td>\n",
       "      <td>67.000</td>\n",
       "      <td>93.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>159.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_max</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>164.025400</td>\n",
       "      <td>17.944183</td>\n",
       "      <td>122.0</td>\n",
       "      <td>152.000</td>\n",
       "      <td>162.000</td>\n",
       "      <td>174.000</td>\n",
       "      <td>238.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>4.068203</td>\n",
       "      <td>2.949386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>18.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>0.323612</td>\n",
       "      <td>0.706059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_mode</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>137.452023</td>\n",
       "      <td>16.381289</td>\n",
       "      <td>60.0</td>\n",
       "      <td>129.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>148.000</td>\n",
       "      <td>187.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_mean</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>134.610536</td>\n",
       "      <td>15.593596</td>\n",
       "      <td>73.0</td>\n",
       "      <td>125.000</td>\n",
       "      <td>136.000</td>\n",
       "      <td>145.000</td>\n",
       "      <td>182.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_median</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>138.090310</td>\n",
       "      <td>14.466589</td>\n",
       "      <td>77.0</td>\n",
       "      <td>129.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>148.000</td>\n",
       "      <td>186.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_variance</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>18.808090</td>\n",
       "      <td>28.977636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>269.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_tendency</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>0.320320</td>\n",
       "      <td>0.610829</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fetal_health</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>1.304327</td>\n",
       "      <td>0.614377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  count        mean        std    min  \\\n",
       "baseline_value                   2126.0  133.303857   9.840844  106.0   \n",
       "accelerations                    2126.0    0.003178   0.003866    0.0   \n",
       "fetal_movement                   2126.0    0.009481   0.046666    0.0   \n",
       "uterine_contractions             2126.0    0.004366   0.002946    0.0   \n",
       "light_decelerations              2126.0    0.001889   0.002960    0.0   \n",
       "severe_decelerations             2126.0    0.000003   0.000057    0.0   \n",
       "prolongued_decelerations         2126.0    0.000159   0.000590    0.0   \n",
       "short_term_variability_abnormal  2126.0   46.990122  17.192814   12.0   \n",
       "short_term_variability_mean      2126.0    1.332785   0.883241    0.2   \n",
       "long_term_variability_abnormal   2126.0    9.846660  18.396880    0.0   \n",
       "long_term_variability_mean       2126.0    8.187629   5.628247    0.0   \n",
       "histogram_width                  2126.0   70.445908  38.955693    3.0   \n",
       "histogram_min                    2126.0   93.579492  29.560212   50.0   \n",
       "histogram_max                    2126.0  164.025400  17.944183  122.0   \n",
       "histogram_number_of_peaks        2126.0    4.068203   2.949386    0.0   \n",
       "histogram_number_of_zeroes       2126.0    0.323612   0.706059    0.0   \n",
       "histogram_mode                   2126.0  137.452023  16.381289   60.0   \n",
       "histogram_mean                   2126.0  134.610536  15.593596   73.0   \n",
       "histogram_median                 2126.0  138.090310  14.466589   77.0   \n",
       "histogram_variance               2126.0   18.808090  28.977636    0.0   \n",
       "histogram_tendency               2126.0    0.320320   0.610829   -1.0   \n",
       "fetal_health                     2126.0    1.304327   0.614377    1.0   \n",
       "\n",
       "                                     25%      50%      75%      max  \n",
       "baseline_value                   126.000  133.000  140.000  160.000  \n",
       "accelerations                      0.000    0.002    0.006    0.019  \n",
       "fetal_movement                     0.000    0.000    0.003    0.481  \n",
       "uterine_contractions               0.002    0.004    0.007    0.015  \n",
       "light_decelerations                0.000    0.000    0.003    0.015  \n",
       "severe_decelerations               0.000    0.000    0.000    0.001  \n",
       "prolongued_decelerations           0.000    0.000    0.000    0.005  \n",
       "short_term_variability_abnormal   32.000   49.000   61.000   87.000  \n",
       "short_term_variability_mean        0.700    1.200    1.700    7.000  \n",
       "long_term_variability_abnormal     0.000    0.000   11.000   91.000  \n",
       "long_term_variability_mean         4.600    7.400   10.800   50.700  \n",
       "histogram_width                   37.000   67.500  100.000  180.000  \n",
       "histogram_min                     67.000   93.000  120.000  159.000  \n",
       "histogram_max                    152.000  162.000  174.000  238.000  \n",
       "histogram_number_of_peaks          2.000    3.000    6.000   18.000  \n",
       "histogram_number_of_zeroes         0.000    0.000    0.000   10.000  \n",
       "histogram_mode                   129.000  139.000  148.000  187.000  \n",
       "histogram_mean                   125.000  136.000  145.000  182.000  \n",
       "histogram_median                 129.000  139.000  148.000  186.000  \n",
       "histogram_variance                 2.000    7.000   24.000  269.000  \n",
       "histogram_tendency                 0.000    0.000    1.000    1.000  \n",
       "fetal_health                       1.000    1.000    1.000    3.000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that all of the values are of type float and there are no missing values, which is great.\n",
    "\n",
    "Let's divide the data into attributes and targets, scale the attributes using the MinMaxScaler for normalization and convert the target classes into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_attributes = ctg_data.drop('fetal_health', axis=1)\n",
    "ctg_targets = ctg_data['fetal_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(ctg_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_attributes_scaled = scaler.transform(ctg_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_targets = ctg_targets.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have separated the target variable from the rest, let's see how the classess are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1655\n",
       "2     295\n",
       "3     176\n",
       "Name: fetal_health, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg_targets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctg_targets.value_counts().plot(kind='bar')\n",
    "\n",
    "plt.title(\"Distribution of target classes\")\n",
    "plt.xlabel(\"Fetal health\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(ticks=[0, 1, 2], labels=[\"Normal\", \"Suspicious\", \"Pathological\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last thing to do before moving on to choosing and training algorithms will be to split the data into training and testing sets. The default options of the `train_test_split` method will be used to split the data - 25% of it will be left for testing and 75% used for training. Since the target classes are not equally distributed, as can be seen above, stratification based on the target variable will be used when splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_attributes_train, ctg_attributes_test, ctg_targets_train, ctg_targets_test = train_test_split(\n",
    "    ctg_attributes_scaled, ctg_targets, stratify=ctg_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes of the new sets are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes training set size: 1594 (with 21 attributes)\n",
      "Targets training set size: 1594\n"
     ]
    }
   ],
   "source": [
    "print(f\"Attributes training set size: {ctg_attributes_train.shape[0]} (with {ctg_attributes_train.shape[1]} attributes)\")\n",
    "print(f\"Targets training set size: {ctg_targets_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes testing set size: 532 (with 21 attributes)\n",
      "Targets testing set size: 532\n"
     ]
    }
   ],
   "source": [
    "print(f\"Attributes testing set size: {ctg_attributes_test.shape[0]} (with {ctg_attributes_test.shape[1]} attributes)\")\n",
    "print(f\"Targets testing set size: {ctg_targets_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "As the task at hand represents a classification problem, the first algorithm to be trained on the data will be a logistic regression. Let's start with a \"plain\" model and see a classification report on the scoring metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_logistic_regression = LogisticRegression().fit(ctg_attributes_train, ctg_targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.97      0.95      1241\n",
      "           2       0.71      0.59      0.64       221\n",
      "           3       0.85      0.70      0.77       132\n",
      "\n",
      "    accuracy                           0.89      1594\n",
      "   macro avg       0.83      0.75      0.78      1594\n",
      "weighted avg       0.89      0.89      0.89      1594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ctg_targets_train, plain_logistic_regression.predict(ctg_attributes_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scoring of the model looks very good for the first class and not so bad for the other two. It can also be seen that accuracy and F1-score are comparable. Nevertheless since we are dealing with imbalanced data with a multiclass target variable, F1-score with weighted average will be used as a scoring metric.\n",
    "\n",
    "So in order to find the best scoring model, first the best combination of hyperparameters must be found. This can be done using a grid search cross validation. The hyperparameters and the ranges from which they will be optimized are the following:\n",
    "\n",
    "* `C`: 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000\n",
    "* `max_iter`: 100, 500, 1000, 10000\n",
    "* `fit_intercept`: True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgr = {\n",
    "    \"C\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "    \"max_iter\": [100, 500, 1000, 10000],\n",
    "    \"fit_intercept\": [True, False],\n",
    "}\n",
    "\n",
    "grid_search_lgr = GridSearchCV(estimator=LogisticRegression(), param_grid=params_lgr, scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000,\n",
       "                               10000],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'max_iter': [100, 500, 1000, 10000]},\n",
       "             scoring='f1_weighted')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lgr.fit(ctg_attributes_train, ctg_targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = grid_search_lgr.best_estimator_\n",
    "logistic_regression_train_score = grid_search_lgr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator is LogisticRegression(C=100) with a score of 0.8897259971573341\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best estimator is {logistic_regression} with a score of {logistic_regression_train_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a good score and it seems the number of maximum iterations is not important in this case so it can be removed from the grid search parameters, but for now I will leave it as it is.\n",
    "\n",
    "Now let's move on to some trees and forests and see how those algorithms will perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "\n",
    "We have already decided on the scoring metric and what we have to do now is again fine-tune the important hyperparameters of the model. This will be done again using grid search cross validation. The hyperparamteres to be optimized here are the following:\n",
    "\n",
    "* `max_depth`: 1, 3, 5, 7, 9, 11, 13, 15\n",
    "* `min_samples_leaf`: 2, 5, 10, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dt = {\n",
    "    \"max_depth\": [1, 3, 5, 7, 9, 11, 13, 15],\n",
    "    \"min_samples_leaf\": [2, 5, 10, 12],\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=params_dt, scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 3, 5, 7, 9, 11, 13, 15],\n",
       "                         'min_samples_leaf': [2, 5, 10, 12]},\n",
       "             scoring='f1_weighted')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_dt.fit(ctg_attributes_train, ctg_targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator is DecisionTreeClassifier(max_depth=9, min_samples_leaf=2) with a score of 0.924544447057165\n"
     ]
    }
   ],
   "source": [
    "decision_tree = grid_search_dt.best_estimator_\n",
    "decision_tree_train_score = grid_search_dt.best_score_\n",
    "print(f\"The best estimator is {decision_tree} with a score of {decision_tree_train_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the decision tree classifier is performing better than the logistic regression. Let's see how a random forest will do with the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "Same as before we will first optimize the hyperparameters of the model to choose the best estimator. The hyperparameters and their ranges here are:\n",
    "\n",
    "* `n_estimators`: 100, 200, 300, 400, 500\n",
    "* `max_depth`: 10, 20, 50, 100, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_depth\": [10, 20, 50, 100, 200],\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=params_rf, scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [10, 20, 50, 100, 200],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
       "             scoring='f1_weighted')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.fit(ctg_attributes_train, ctg_targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator is RandomForestClassifier(max_depth=50, n_estimators=400) with a score of 0.9398809762481243\n"
     ]
    }
   ],
   "source": [
    "random_forest = grid_search_rf.best_estimator_\n",
    "random_forest_train_score = grid_search_rf.best_score_\n",
    "print(f\"The best estimator is {random_forest} with a score of {random_forest_train_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the decision tree seems to have the best score among the trained algorithms. Before comparing the performance of all the models on the testing data, let's add two more using support vector machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Support Vector Classifier\n",
    "\n",
    "We will perform the already known steps with the following hyperparameter:\n",
    "\n",
    "* `C`: 0.01, 0.1, 1, 10, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ln_svc = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "grid_search_ln_svc = GridSearchCV(estimator=LinearSVC(), param_grid=params_ln_svc, scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Toni\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LinearSVC(), param_grid={'C': [0.01, 0.1, 1, 10, 100]},\n",
       "             scoring='f1_weighted')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_ln_svc.fit(ctg_attributes_train, ctg_targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator is LinearSVC(C=10) with a score of 0.8889771279276207\n"
     ]
    }
   ],
   "source": [
    "linear_svc = grid_search_ln_svc.best_estimator_\n",
    "linear_svc_train_score = grid_search_ln_svc.best_score_\n",
    "print(f\"The best estimator is {linear_svc} with a score of {linear_svc_train_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Support Vector Classifier\n",
    "\n",
    "One last time we will run a grid search cross validation to find the best scoring gaussian support vector classifier. To do so, the following hyperparameteres will be tuned:\n",
    "\n",
    "* `C`: 0.1, 1, 10, 20, 100, 200, 500\n",
    "* `gamma`: 0.01, 0.05, 0.1, 0.5, 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_g_svc = {\n",
    "    \"C\": [0.1, 1, 10, 20, 100, 200, 500],\n",
    "    \"gamma\": [0.01, 0.05, 0.1, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "grid_search_g_svc = GridSearchCV(estimator=SVC(), param_grid=params_g_svc, scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 20, 100, 200, 500],\n",
       "                         'gamma': [0.01, 0.05, 0.1, 0.5, 0.7]},\n",
       "             scoring='f1_weighted')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_g_svc.fit(ctg_attributes_train, ctg_targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator is SVC(C=100, gamma=0.5) with a score of 0.9234446938858808\n"
     ]
    }
   ],
   "source": [
    "gaussian_svc = grid_search_g_svc.best_estimator_\n",
    "gaussian_svc_train_score = grid_search_g_svc.best_score_\n",
    "print(f\"The best estimator is {gaussian_svc} with a score of {gaussian_svc_train_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the best scoring model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the models on the training set of the data and choosing the best estimator from each type, now it's time to compare their performances and choose the best from the best.\n",
    "\n",
    "In order to do that, each model will be tested with the testing data and scored using the F1-score with weighted average.\n",
    "\n",
    "To make things a bit easier and cleaner, let's create a function that returns the F1-score value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(model, test_attributes, y_true):\n",
    "    y_predicted = model.predict(test_attributes)\n",
    "    return f1_score(y_true, y_predicted, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_test_score = get_f1_score(logistic_regression, ctg_attributes_test, ctg_targets_test)\n",
    "\n",
    "decision_tree_test_score = get_f1_score(decision_tree, ctg_attributes_test, ctg_targets_test)\n",
    "random_forest_test_score = get_f1_score(random_forest, ctg_attributes_test, ctg_targets_test)\n",
    "\n",
    "linear_svc_test_score = get_f1_score(linear_svc, ctg_attributes_test, ctg_targets_test)\n",
    "gaussian_svc_test_score = get_f1_score(gaussian_svc, ctg_attributes_test, ctg_targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing scores:\n",
      "Logistic Regression: 0.9093061543719438\n",
      "Decision Tree CLassifier: 0.9175916642341325\n",
      "Random Forest Classifier: 0.9348694793201515\n",
      "Linear Support Vector Classifier: 0.9007844712048831\n",
      "Gaussian Support Vector Classifier: 0.925835182027478\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing scores:\")\n",
    "print(f\"Logistic Regression: {logistic_regression_test_score}\")\n",
    "print(f\"Decision Tree CLassifier: {decision_tree_test_score}\")\n",
    "print(f\"Random Forest Classifier: {random_forest_test_score}\")\n",
    "print(f\"Linear Support Vector Classifier: {linear_svc_test_score}\")\n",
    "print(f\"Gaussian Support Vector Classifier: {gaussian_svc_test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model with the current data is the random forest classifier with approximately 0.94 testing score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "A couple of classification algorithms were tested for the prediction of fetal health from available data of CTG features. All of them performed rather high, but the best one of those algorithms proved to be the random forest classifier which can identify with 94% certainty the correct fetal condition, as classified by professionals in the field.\n",
    "\n",
    "What this analysis shows us is that the data obtained from the SisPorto program in combination with one of the trained algorithms, preferably the random forest classifier, can be useful when classifing fetal health condition in regards to the basic CTG features that are measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "   1.\thttps://archive.ics.uci.edu/ml/datasets/cardiotocography\n",
    "   2.\thttps://www.kaggle.com/andrewmvd/fetal-health-classification\n",
    "   3.\tAyres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318 (https://pubmed.ncbi.nlm.nih.gov/11132590/)\n",
    "   4.\tChristian M. Pettker, Katherine H. Campbell, Antepartum Fetal Assessment in Avery's Diseases of the Newborn (Tenth Edition), 2018\n",
    "   5.\thttps://en.wikipedia.org/wiki/Cardiotocography\n",
    "   6.\thttps://geekymedics.com/how-to-read-a-ctg/\n",
    "   7.\tD. Ayres-de-Campos et al. / International Journal of Gynecology and Obstetrics 131 (2015) 13â€“24 (https://obgyn.onlinelibrary.wiley.com/doi/epdf/10.1016/j.ijgo.2015.06.020 )\n",
    "   8. Scikit-learn documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
